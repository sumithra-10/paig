{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e69bb50d-b560-4d92-b8aa-51b3d10fecad",
      "metadata": {
        "id": "e69bb50d-b560-4d92-b8aa-51b3d10fecad"
      },
      "source": [
        "# PAIG - Prompt/Reply Guardrails and Observability using OpenAI\n",
        "\n",
        "This notebook demonstrates how PAIG protects prompts and replies when using OpenAI, as well as how to achieve end-to-end observability.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **OpenAI API Key**: Required to make API calls to OpenAI.\n",
        "\n",
        "> The sample prompt is around 12 tokens, and the reply is 15 tokens. The notebook uses the model `gpt-4o-mini`, which currently costs \\$0.150 per 1 million input tokens and \\$0.600 per 1 million output tokens. Therefore, each prompt/reply costs approximately \\$0.00002.\n",
        "\n",
        "## Details\n",
        "\n",
        "This notebook covers the following steps:\n",
        "\n",
        "1. Install Python packages including PAIG Shield Server, PAIG Shield Client, OpenAI, and Spacy models.\n",
        "2. Start the PAIG Shield Server.\n",
        "3. Verify that the PAIG Shield Server is up and accepting requests.\n",
        "4. Download the sample application configuration from the PAIG Shield Server.\n",
        "5. Configure the OpenAI API Key.\n",
        "6. Write a simple application Using OpenAI.\n",
        "7. Write a simple application using OpenAI and the PAIG Shield Client.\n",
        "8. Test a sample prompt.\n",
        "9. Test sample prompts with UI.\n",
        "10. Review access audits in the PAIG Shield Server.\n",
        "11. Review Application Permissions.\n",
        "12. Check the reports.\n",
        "\n",
        "## Exceptions and Assumptions\n",
        "\n",
        "1. For simplicity, authentication to the PAIG Shield Server is turned off.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e821fc23-5f14-49f3-bacb-1d785cffa94b",
      "metadata": {
        "id": "e821fc23-5f14-49f3-bacb-1d785cffa94b"
      },
      "source": [
        "# 1. Install Python Packages\n",
        "\n",
        "This step installs the necessary Python packages for PAIG Shield Server, PAIG Shield Client, OpenAI, and Spacy.\n",
        "\n",
        "> Note:\n",
        "> 1. It might take a minute or more to download and install all the packages.\n",
        "> 2. After everything is installed, you might see a message to restart the runtime. You can ignore this message.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba361f69-5dde-471f-ad0a-8daa9a049e88",
      "metadata": {
        "id": "ba361f69-5dde-471f-ad0a-8daa9a049e88"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq paig_client openai paig-server --no-warn-conflicts\n",
        "!python -m spacy download en_core_web_lg\n",
        "!echo \"\\n\\n\"\n",
        "!echo \"Ignore the above messages to restart the runtime or kernel. Please continue to the next step\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e2e478-7777-4f9d-9056-0262ef6de25e",
      "metadata": {
        "id": "34e2e478-7777-4f9d-9056-0262ef6de25e"
      },
      "source": [
        "# 2. Start the PAIG Shield Server\n",
        "\n",
        "The command line to start PAIG Shield Server is `paig run`. The server will be started in the background using Python subprocess.\n",
        "\n",
        "The default port used by PAIG Shield Server is 4545.\n",
        "\n",
        "> **Tip:** Detailed PAIG application logs can be found in a directory called \"logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deccf140-571a-4330-a7d5-3c1d87cf1397",
      "metadata": {
        "id": "deccf140-571a-4330-a7d5-3c1d87cf1397"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "command = [\"paig\", \"run\"]\n",
        "\n",
        "# Start the PAIG application in the background\n",
        "# Note - Console logs are hidden using stdout parameter, please remove the stdout parameter to get console logs\n",
        "process = subprocess.Popen(command, stdout=subprocess.DEVNULL)\n",
        "\n",
        "print(f\"Started PAIG application with PID {process.pid}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "__XLMSPOLIDl",
      "metadata": {
        "id": "__XLMSPOLIDl"
      },
      "source": [
        "\n",
        "# 3. Verify that the PAIG Shield Server is Up and Accepting Requests\n",
        "\n",
        "This step ensures that the PAIG Shield Server is running and accepting requests. Once the server is up and running, it will print the URL for the PAIG Shield Server.\n",
        "\n",
        "> Note: The URL generated will be accessible from outside.  But it may take several seconds for the first load.  The portal will be opened within this Colab notebook in a later step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NZQG-tzDLIDm",
      "metadata": {
        "id": "NZQG-tzDLIDm"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "url = \"http://127.0.0.1:4545/\"\n",
        "\n",
        "print('Please wait while we confirm if your PAIG application is ready...')\n",
        "while True:\n",
        "  try:\n",
        "    response = requests.get(url, timeout=3)\n",
        "    response.raise_for_status()\n",
        "    break\n",
        "  except requests.RequestException:\n",
        "    print('Server is not ready yet, please hang on...')\n",
        "    time.sleep(3)\n",
        "\n",
        "server_url = str(eval_js(f\"google.colab.kernel.proxyPort({4545}, {{'cache': true}})\"))\n",
        "print(f'Your PAIG application is now ready!.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77325810-6ae1-47c8-b3d2-62bbf09efbe2",
      "metadata": {
        "id": "77325810-6ae1-47c8-b3d2-62bbf09efbe2"
      },
      "source": [
        "# 4. Download the Application Configuration from the PAIG Shield Server\n",
        "\n",
        "The PAIG Shield Server is bootstrapped with a sample GenAI application, which can be used to quickly test PAIG features. In this step, we will download the configuration file needed by the PAIG Shield Client. The configuration file is saved in the `privacera` sub-folder.\n",
        "\n",
        "> Note: The authentication is disabled in the colab mode only. So in colab mode, the API call to get the configuration will not be authorized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d9ec3d1-b319-460f-aa2b-dc53bccbd746",
      "metadata": {
        "id": "5d9ec3d1-b319-460f-aa2b-dc53bccbd746"
      },
      "outputs": [],
      "source": [
        "CONFIG_URL=\"http://127.0.0.1:4545/governance-service/api/ai/application/1/config/json/download\"\n",
        "OUTPUT_FILE=\"privacera/privacera-shield-PAIG-Demo-config.json\"\n",
        "!mkdir -p privacera && wget -O $OUTPUT_FILE $CONFIG_URL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b6692c7-8fcd-4746-b56f-928d3098f929",
      "metadata": {
        "id": "5b6692c7-8fcd-4746-b56f-928d3098f929"
      },
      "source": [
        "# 5. Configure the OpenAI API Key\n",
        "\n",
        "Enter your OpenAI API key in the text box that will appear when you run this step. After you input the key, press __ENTER__.\n",
        "\n",
        "> Note: It is important to press __ENTER__ for your value to be accepted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "88429864-81be-47e8-9b7b-61d30cfb3f3b",
      "metadata": {
        "id": "88429864-81be-47e8-9b7b-61d30cfb3f3b",
        "outputId": "53b7544b-9288-4979-fc5e-d60a925e8500",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 Enter your OpenAI API key and hit Enter:··········\n",
            "OpenAI key has been entered. Now validating it...\n",
            "Connected to OpenAI successfully! How can I assist you today?\n",
            "If connection to OpenAI is successful, then proceed to the next step.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "openai_api_key = getpass(\"🔑 Enter your OpenAI API key and hit Enter:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "print(\"OpenAI key has been entered. Now validating it...\")\n",
        "\n",
        "from openai import OpenAI\n",
        "openai_model = \"gpt-4o-mini\"\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say Connected to OpenAI successfully!\",\n",
        "        }\n",
        "    ],\n",
        "    model=openai_model,\n",
        ")\n",
        "print(chat_completion.choices[0].message.content)\n",
        "print(\"If connection to OpenAI is successful, then proceed to the next step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Write a Simple Application Using OpenAI"
      ],
      "metadata": {
        "id": "dqkLY6A3fpAA"
      },
      "id": "dqkLY6A3fpAA"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Set the OPENAI_API_KEY environment variable or set it here\n",
        "openai_client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# Function to generate AI responses\n",
        "def generate_response(PROMPT):\n",
        "\n",
        "    try:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=openai_model,\n",
        "            messages=[{\"role\": \"user\", \"content\": PROMPT}],\n",
        "            temperature=0\n",
        "        )\n",
        "        llm_response = response.choices[0].message.content\n",
        "        return llm_response\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# UI Components\n",
        "input_box = widgets.Textarea(\n",
        "    placeholder=\"Enter your prompt here...\",\n",
        "    description=\"Prompt:\",\n",
        "    layout=widgets.Layout(width='100%', height='100px')\n",
        ")\n",
        "\n",
        "output_box = widgets.HTML(\n",
        "    value=\"<p><i>Your response will appear here...</i></p>\",\n",
        "    placeholder=\"Generated response\",\n",
        "    description=\"Output:\"\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate\")\n",
        "\n",
        "# Callback Function\n",
        "def on_generate_clicked(b):\n",
        "    user_prompt = input_box.value\n",
        "    if user_prompt.strip():\n",
        "        output_box.value = \"<p><i>Generating response...</i></p>\"\n",
        "        response = generate_response(user_prompt)\n",
        "        output_box.value = f\"<p><b>Response:</b><br>{response}</p>\"\n",
        "    else:\n",
        "        output_box.value = \"<p><i>Please enter a valid prompt.</i></p>\"\n",
        "\n",
        "# Link Button to Function\n",
        "generate_button.on_click(on_generate_clicked)\n",
        "\n",
        "# Display the UI\n",
        "display(HTML(\"<h2>Generative AI App</h2>\"))\n",
        "display(input_box)\n",
        "display(generate_button)\n",
        "display(output_box)\n"
      ],
      "metadata": {
        "id": "8alIV9lqr3bZ",
        "outputId": "3ef42b64-3ad4-4707-f59e-9a008defcf93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542,
          "referenced_widgets": [
            "06f989ef9c9042649ce3baa4a1c049b5",
            "0ec81053c9104108bacb240ad5cdb77e",
            "05fe3921035e4b0b97c430b08dc7ad6e",
            "10df2c926f21472e966a7127885a8f05",
            "030a1125a9864a139787daed014257fe",
            "1eca99e5a8e84057a36d9ac323628c7f",
            "72e6020ff3384b43821b334a5406c7f5",
            "b7cbf94a835845dda74a1a691f6b88ce",
            "74a978e1d4c0497ebf19dc5af328ce90"
          ]
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>Generative AI App</h2>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='Prompt:', layout=Layout(height='100px', width='100%'), placeholder='Enter your…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06f989ef9c9042649ce3baa4a1c049b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Generate', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10df2c926f21472e966a7127885a8f05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<p><i>Your response will appear here...</i></p>', description='Output:', placeholder='Generated re…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72e6020ff3384b43821b334a5406c7f5"
            }
          },
          "metadata": {}
        }
      ],
      "id": "8alIV9lqr3bZ"
    },
    {
      "cell_type": "markdown",
      "id": "72d9da12-1a03-4cb4-8106-3fbbf4fa674d",
      "metadata": {
        "id": "72d9da12-1a03-4cb4-8106-3fbbf4fa674d"
      },
      "source": [
        "# 7. Write a Simple Application Using OpenAI and the PAIG Shield Client\n",
        "\n",
        "This section demonstrates a simple Python application that uses OpenAI for inference. The PAIG Shield is integrated within the application. The PAIG Shield client is initialized using the `setup()` method and is then used to validate the prompts and replies. In this basic GenAI application, the PAIG Shield's `check_access()` method needs to be explicitly called for the prompt and reply. However, when using frameworks like LangChain, PAIG will automatically instrument the code and call the `check_access()` method for all interactions with LLMs and RAGs.\n",
        "\n",
        "To enforce user or group-specific policies, the calling username should be set as the request context before processing the prompt. This can be done using the `with paig_shield_client.create_shield_context(username=username):` syntax.\n",
        "\n",
        "To stitch together related calls, an optional thread ID can be passed to the `check_access()` method to tie them together.\n",
        "\n",
        "Depending on the policies, the `check_access()` method will perform one of the following actions:\n",
        "\n",
        "1. If the user is not permitted to use the application or if there is a policy to deny contents which are inappropriate, having unauthorized sensitive information, or is of malicious intent, then the method will throw the exception `paig_client.exception.AccessControlException`. This exception can be caught, and an alternate reply can be returned to the caller.\n",
        "2. If the request is permitted but contains PII or sensitive information that is not authorized and needs to be redacted, the method will return the content with the PII or sensitive data elements redacted. This behavior is consistent for prompts, requests to RAGs, replies from RAGs, requests to LLMs, and replies from LLMs.\n",
        "3. If there are no policy violations, the content is returned without any alterations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dc0a93aa-fd6c-4bf7-9136-7d856f6109d1",
      "metadata": {
        "id": "dc0a93aa-fd6c-4bf7-9136-7d856f6109d1",
        "outputId": "40c0b575-917f-49fe-d8ec-f9fb0fb0c8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'paig_client'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2efa15951890>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpaig_client\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpaig_shield_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpaig_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConversationType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaig_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'paig_client'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "\n",
        "from paig_client import client as paig_shield_client\n",
        "from paig_client.model import ConversationType\n",
        "import paig_client.exception\n",
        "from openai import OpenAI\n",
        "import uuid\n",
        "\n",
        "# Set the OPENAI_API_KEY environment variable or set it here\n",
        "openai_client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# PAIG supports frameworks like LangChain and VectorDBs like Milvus, OpenSearch. The integration to be considered should be passed as the frameworks parameter.\n",
        "paig_shield_client.setup(frameworks=[])\n",
        "\n",
        "# Create a function which can be called for the prompts\n",
        "def query_as_user(username, prompt_text):\n",
        "    # Generate a random UUID which will be used to bind a prompt with a reply\n",
        "    privacera_thread_id = str(uuid.uuid4())\n",
        "\n",
        "    try:\n",
        "        with paig_shield_client.create_shield_context(username=username):\n",
        "            print(f\"PROMPT BY USER: {prompt_text}\")\n",
        "\n",
        "            # Validate prompt with Privacera Shield\n",
        "            updated_prompt_text = paig_shield_client.check_access(\n",
        "                text=prompt_text,\n",
        "                conversation_type=ConversationType.PROMPT,\n",
        "                thread_id=privacera_thread_id\n",
        "            )\n",
        "            updated_prompt_text = updated_prompt_text[0].response_text\n",
        "            if prompt_text != updated_prompt_text:\n",
        "                print(f\"Updated Prompt Text: {updated_prompt_text}\")\n",
        "            else:\n",
        "                print(\"PROMPT VALIDATION: Prompt has not been changed by PAIG.\")\n",
        "\n",
        "            # Call LLM with updated prompt text\n",
        "            PROMPT = f\"\"\"Use the following pieces of context to answer the question at the end.\n",
        "            {updated_prompt_text}\n",
        "            ANSWER:\n",
        "            \"\"\"\n",
        "            response = openai_client.chat.completions.create(\n",
        "                model=openai_model,\n",
        "                messages=[{\"role\": \"user\", \"content\": PROMPT}],\n",
        "                temperature=0\n",
        "            )\n",
        "            llm_response = response.choices[0].message.content\n",
        "            print(f\"LLM Response: {llm_response}\")\n",
        "\n",
        "            # Validate LLM response with Privacera Shield\n",
        "            updated_reply_text = paig_shield_client.check_access(\n",
        "                text=llm_response,\n",
        "                conversation_type=ConversationType.REPLY,\n",
        "                thread_id=privacera_thread_id\n",
        "            )\n",
        "            updated_reply_text = updated_reply_text[0].response_text\n",
        "            if llm_response != updated_reply_text:\n",
        "                print(f\"REPLY VALIDATION (UPDATED BY PAIG): {updated_reply_text}\")\n",
        "            else:\n",
        "                print(\"REPLY VALIDATION: The reply has not been updated by PAIG.\")\n",
        "            return updated_reply_text\n",
        "    except paig_client.exception.AccessControlException as e:\n",
        "        # If access is denied, this exception will be thrown. Handle it accordingly.\n",
        "        print(\"The query has been denied!\")\n",
        "        print(f\"AccessControlException: {e}\")\n",
        "        return \"DENIED: Prompt is not authorized.\"\n",
        "print(\"PAIG Shield setup successfully completed! You can now proceed to the next step.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "033b73ac-0a25-4a72-a32a-ba53c0d814db",
      "metadata": {
        "id": "033b73ac-0a25-4a72-a32a-ba53c0d814db"
      },
      "source": [
        "\n",
        "# 8. Test a Sample Prompt\n",
        "\n",
        "We will call the method `query_as_user` using a test user named `sally` with a sample prompt.\n",
        "\n",
        "Since we are using the demo application configuration, which has a policy that redacts PERSON_NAME from replies, any elements matching the policy in the LLM's reply will be redacted before responding back to the caller.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d6091c-0eee-4e7f-bd8f-3a9224f2d001",
      "metadata": {
        "id": "43d6091c-0eee-4e7f-bd8f-3a9224f2d001"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Using test user named sally\n",
        "reply = query_as_user(\"sally\", \"Who was the first President of USA and where did they live?\")\n",
        "print(f\"REPLY TO USER={reply}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Test sample prompts with UI"
      ],
      "metadata": {
        "id": "7NWelYo7geSB"
      },
      "id": "7NWelYo7geSB"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import html\n",
        "\n",
        "\n",
        "# Function to generate AI responses\n",
        "def generate_response(PROMPT):\n",
        "\n",
        "    try:\n",
        "        llm_response = query_as_user(\"sally\", PROMPT)\n",
        "        return llm_response\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# UI Components\n",
        "input_box = widgets.Textarea(\n",
        "    placeholder=\"Enter your prompt here...\",\n",
        "    description=\"Prompt:\",\n",
        "    layout=widgets.Layout(width='100%', height='100px')\n",
        ")\n",
        "\n",
        "output_box = widgets.HTML(\n",
        "    value=\"<p><i>Your response will appear here...</i></p>\",\n",
        "    placeholder=\"Generated response\",\n",
        "    description=\"Output:\"\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate\")\n",
        "\n",
        "# Callback Function\n",
        "def on_generate_clicked(b):\n",
        "    user_prompt = input_box.value\n",
        "    if user_prompt.strip():\n",
        "        output_box.value = \"<p><i>Generating response...</i></p>\"\n",
        "        response = generate_response(user_prompt)\n",
        "        sanitized_response = html.escape(response)\n",
        "        output_box.value = f\"<p><b>Response:</b><br>{sanitized_response}</p>\"\n",
        "    else:\n",
        "        output_box.value = \"<p><i>Please enter a valid prompt.</i></p>\"\n",
        "\n",
        "# Link Button to Function\n",
        "generate_button.on_click(on_generate_clicked)\n",
        "\n",
        "# Display the UI\n",
        "display(HTML(\"<h2>Generative AI App</h2>\"))\n",
        "display(input_box)\n",
        "display(generate_button)\n",
        "display(output_box)\n"
      ],
      "metadata": {
        "id": "q7t7Be52t6hC"
      },
      "id": "q7t7Be52t6hC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "V1xv0cN3PT07",
      "metadata": {
        "id": "V1xv0cN3PT07"
      },
      "source": [
        "# 10. Review Access Audits in the PAIG Shield Server\n",
        "\n",
        "In this step, we will open the PAIG Server portal and check the audits. The portal will be embedded within this notebook.\n",
        "\n",
        "1. In the PAIG portal, navigate to the `Security > Access Audits` section. You will see the audit record from the above request.\n",
        "2. Click on the `More Details` button to see the details of the prompts sent by the application to the LLM and the responses coming from the LLM.\n",
        "3. PAIG will identify all PII and sensitive data and tag them.\n",
        "4. The default policy is to redact PERSON_NAME, so the president's name will be redacted before being sent to the caller.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lUoz5qhFPT07",
      "metadata": {
        "id": "lUoz5qhFPT07"
      },
      "outputs": [],
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "audit_url = f'{server_url}#/audits_security'\n",
        "IFrame(src=audit_url, width=\"100%\", height=1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F_ak1pfa7czI",
      "metadata": {
        "id": "F_ak1pfa7czI"
      },
      "source": [
        "\n",
        "# 11. Review Application Permissions\n",
        "\n",
        "1. In the portal, go to `Application -> AI Applications -> PAIG Demo`.\n",
        "2. Click on the `PERMISSIONS` tab at the top.\n",
        "3. You will see a policy stating that any reply containing `PERSON`, `EMAIL_ADDRESS`, or `PHONE_NUMBER` should be redacted.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddEvs8X_8ghM",
      "metadata": {
        "id": "ddEvs8X_8ghM"
      },
      "source": [
        "\n",
        "# 12. Check the Reports\n",
        "\n",
        "1. Click on `Reports -> Built-in Reports -> Sensitive Data Access Overview`.\n",
        "2. This report provides statistics on the PII and other sensitive data found in the prompts and replies.\n",
        "3. Similarly, the report `Summary of Users who accessed the GenAI Application` will provide details about the GenAI applications and the users accessing them.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06f989ef9c9042649ce3baa4a1c049b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0ec81053c9104108bacb240ad5cdb77e",
            "placeholder": "Enter your prompt here...",
            "rows": null,
            "style": "IPY_MODEL_05fe3921035e4b0b97c430b08dc7ad6e",
            "value": "which Engineering field is good these days"
          }
        },
        "0ec81053c9104108bacb240ad5cdb77e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "100px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "05fe3921035e4b0b97c430b08dc7ad6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10df2c926f21472e966a7127885a8f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generate",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_030a1125a9864a139787daed014257fe",
            "style": "IPY_MODEL_1eca99e5a8e84057a36d9ac323628c7f",
            "tooltip": ""
          }
        },
        "030a1125a9864a139787daed014257fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eca99e5a8e84057a36d9ac323628c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "72e6020ff3384b43821b334a5406c7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "Output:",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7cbf94a835845dda74a1a691f6b88ce",
            "placeholder": "Generated response",
            "style": "IPY_MODEL_74a978e1d4c0497ebf19dc5af328ce90",
            "value": "<p><b>Response:</b><br>The choice of a good engineering field can depend on various factors, including job market trends, personal interests, and technological advancements. As of 2023, here are some engineering fields that are particularly promising:\n\n1. **Software Engineering**: With the ongoing digital transformation, software engineers are in high demand across various industries, including tech, finance, healthcare, and more.\n\n2. **Data Engineering and Data Science**: As organizations increasingly rely on data-driven decision-making, professionals who can manage and analyze data are highly sought after.\n\n3. **Artificial Intelligence and Machine Learning**: Engineers specializing in AI and ML are crucial for developing intelligent systems and applications, making this a rapidly growing field.\n\n4. **Cybersecurity Engineering**: With the rise in cyber threats, cybersecurity engineers are essential for protecting systems and data, making this a critical and in-demand field.\n\n5. **Renewable Energy Engineering**: As the world shifts towards sustainable energy sources, engineers in solar, wind, and other renewable technologies are increasingly needed.\n\n6. **Biomedical Engineering**: This field combines engineering principles with medical sciences to develop technologies and devices that improve healthcare.\n\n7. **Robotics Engineering**: With advancements in automation and robotics, this field is growing in industries such as manufacturing, healthcare, and logistics.\n\n8. **Civil Engineering (Sustainable Infrastructure)**: As urbanization continues, civil engineers focusing on sustainable and resilient infrastructure are in demand.\n\n9. **Environmental Engineering**: With increasing awareness of environmental issues, engineers who can design solutions for pollution control and sustainable practices are needed.\n\n10. **Aerospace Engineering**: With advancements in space exploration and aviation technology, aerospace engineers are in demand for both commercial and defense applications.\n\nUltimately, the best field for you will depend on your interests, strengths, and the specific opportunities available in your region or desired industry. It's also beneficial to stay updated on industry trends and emerging technologies.</p>"
          }
        },
        "b7cbf94a835845dda74a1a691f6b88ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a978e1d4c0497ebf19dc5af328ce90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}